{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Monitor\n",
    "---\n",
    "\n",
    "Pulls data from NVIDIA-SMI output and saves it as a time-series. Commits data to TXT and CSV format for ease of reading and graphing respectively.\n",
    "\n",
    "---\n",
    "\n",
    "## <a name=\"toc\"></a> Table of Contents\n",
    "1. [Proof of Concept](#proof-of-concept)\n",
    "    1. [Capture Raw Status Data](#capture-raw-status-data)\n",
    "    2. [Parse Raw Status Data](#parse-raw-status-data)\n",
    "    3. [Logging to TXT](#logging-to-txt)\n",
    "    4. [Logging to CSV](#logging-to-csv)\n",
    "2. [Object Oriented Approach](#object-oriented-approach)\n",
    "3. [Automated Reporting](#automated-reporting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"proof-of-concept\"></a> [Proof of Concept](#toc)\n",
    "\n",
    "Purely functional code, reduced functions representing the core tasks of the program.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"capture-raw-status-data\"></a> [Capture Raw Status Data](#toc)\n",
    "\n",
    "By running the NVIDIA-SMI command, we obtain real-time status data for the GPUs installed on the machine. Using the native Python `os` module, this raw output can be captured from the terminal and saved by the local program for processing. Consequently, this procedure provides us with a window into the GPUs core sensors, providing us with valuable data to protect our assets from overheating or over-utilization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thu Mar  4 13:32:39 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.64       Driver Version: 430.64       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "|  0%   98C    P0     1W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------- RUN AND CAPTURE TERMINAL -------------------- #\n",
    "\n",
    "import os\n",
    "\n",
    "def get_raw_status_data(debug = False):\n",
    "    if not debug:\n",
    "        return os.popen('nvidia-smi').read()\n",
    "    else:\n",
    "        return \"\"\"\n",
    "Thu Mar  4 13:32:39 2021       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 430.64       Driver Version: 430.64       CUDA Version: 10.1     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  GeForce RTX 208...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
    "|  0%   98C    P0     1W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                       GPU Memory |\n",
    "|  GPU       PID   Type   Process name                             Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "\"\"\"\n",
    "\n",
    "raw_status_data = get_raw_status_data(debug=True)\n",
    "print(raw_status_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"parsing-raw-status-data\"></a> [Parsing Raw Status Data](#toc)\n",
    "\n",
    "The NVIDIA-SMI status output is excellent for a human to read and comprehend but useless for logging. Using native string functions, we can rip and tear at the raw data to extract meaningful information that we can [log as txt](#txt) or [as csv](#csv).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': '04',\n",
       " 'month': '03',\n",
       " 'year': '2021',\n",
       " 'temperature': '98',\n",
       " 'time': '13:32:39',\n",
       " 'fan': '0',\n",
       " 'utilization': '0',\n",
       " 'memory used': '0',\n",
       " 'memory max': '11019',\n",
       " 'power used': '1',\n",
       " 'power max': '250'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- PARSE NVIDIA SMI OUTPUT -------------------- #\n",
    "\n",
    "def parse_day_term(status_terms):\n",
    "    day = status_terms[2]\n",
    "    if len(day) == 1:\n",
    "        day = \"0\" + day\n",
    "    return day\n",
    "\n",
    "\n",
    "def parse_month_term(status_terms):\n",
    "    months_str = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\",\\\n",
    "                  \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "    months_num = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \\\n",
    "                  \"09\", \"10\", \"11\", \"12\"]\n",
    "    months_map = dict(zip(months_str, months_num))\n",
    "    return months_map[status_terms[1]]\n",
    "\n",
    "\n",
    "def parse_year_term(status_terms):\n",
    "    return status_terms[4]\n",
    "\n",
    "\n",
    "def parse_time_term(status_terms):\n",
    "    return status_terms[3]\n",
    "\n",
    "\n",
    "def string_int(string):\n",
    "    try:\n",
    "        _ = int(string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def parse_temperature_term(status_terms):\n",
    "    for status_term in status_terms:\n",
    "        if status_term[-1] == \"C\" and string_int(status_term[:-1]):\n",
    "            return status_term[:-1]\n",
    "    return 1\n",
    "\n",
    "\n",
    "def parse_memory_term(status_terms):\n",
    "    memory = list()\n",
    "    for status_term in status_terms:\n",
    "        if status_term[-3:] == \"MiB\":\n",
    "            memory.append(status_term.split('MiB')[0])\n",
    "    return memory\n",
    "\n",
    "\n",
    "def parse_power_term(status_terms):\n",
    "    power = list()\n",
    "    for status_term in status_terms:\n",
    "        if status_term[-1] == \"W\":\n",
    "            power.append(status_term.split('W')[0])\n",
    "    return power\n",
    "\n",
    "\n",
    "def parse_fan_term(status_terms):\n",
    "    for i in range(len(status_terms)):\n",
    "        status_term = status_terms[i]\n",
    "        if status_term[-1] == \"%\":\n",
    "            # If the last two terms are equal, then they must\n",
    "            # be \"||\" characters defining the wall of the raw\n",
    "            # status data. Ergo, we found the utilization %.\n",
    "            if status_terms[i-1] == status_terms[i-2]:\n",
    "                fan = status_term.split(\"%\")[0]\n",
    "    return fan\n",
    "\n",
    "\n",
    "def parse_utilization_term(status_terms):\n",
    "    for term_i in range(len(status_terms)):\n",
    "        status_term = status_terms[term_i]\n",
    "        if status_term[-1] == \"%\":\n",
    "            # If the last two terms are not equal, then we found\n",
    "            # the utilization % in the middle of the raw status\n",
    "            # data since it's not up against a \"||\" wall.\n",
    "            if status_terms[term_i-1] != status_terms[term_i-2]:\n",
    "                utilization = status_term.split(\"%\")[0]\n",
    "    return utilization\n",
    "\n",
    "\n",
    "def parse_raw_status_data(raw_status_data):\n",
    "    status_terms = raw_status_data.split()\n",
    "    status = dict()\n",
    "    status[\"day\"] = parse_day_term(status_terms)\n",
    "    status[\"month\"] = parse_month_term(status_terms)\n",
    "    status[\"year\"] = parse_year_term(status_terms)\n",
    "    status[\"temperature\"] = parse_temperature_term(status_terms)\n",
    "    status[\"time\"] = parse_time_term(status_terms)\n",
    "    status[\"fan\"] = parse_fan_term(status_terms)\n",
    "    status[\"utilization\"] = parse_utilization_term(status_terms)\n",
    "    status[\"memory used\"] = parse_memory_term(status_terms)[0]\n",
    "    status[\"memory max\"] = parse_memory_term(status_terms)[1]\n",
    "    status[\"power used\"] = parse_power_term(status_terms)[0]\n",
    "    status[\"power max\"] = parse_power_term(status_terms)[1]\n",
    "    return status\n",
    "\n",
    "\n",
    "#### TEST ####\n",
    "status = parse_raw_status_data(raw_status_data)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"logging-to-txt\"></a> [Logging to TXT](#toc)\n",
    "\n",
    "From within the terminal, we need a logfile that is easily interpreted by a human using less, more, or an editor like vim or emacs. Text files easily satisfy this requirement and can be printed in a pretty format for politeness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- TEXT OUTPUT -------------------- #\n",
    "\n",
    "def format_txt_log_entry(status):\n",
    "    return f\"[{status['day']}-{status['month']}\" \\\n",
    "           f\"-{status['year']} @ {status['time']}] >\" \\\n",
    "           f\"  Temp: {status['temperature']}C\" \\\n",
    "           f\"  Power: {status['power used']}/{status['power max']} W\" \\\n",
    "           f\"  Fan: {status['fan']}%\" \\\n",
    "           f\"  Utilization: {status['utilization']}%\" \\\n",
    "           f\"  Memory: {status['memory used']}/{status['memory max']} MiB\\n\"\n",
    "    \n",
    "\n",
    "def write_status_to_txt_logfile(status, txt_logfile):\n",
    "    __func__ = \"write_status_to_txt_logfile\"\n",
    "    try:\n",
    "        with open(txt_logfile, mode=\"a\") as file:\n",
    "            entry = format_txt_log_entry(status)\n",
    "            file.write(entry)\n",
    "            file.close()\n",
    "        return 0\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error in {__func__}: {txt_logfile} not found.\")\n",
    "        return 1\n",
    "    except KeyError:\n",
    "        print(f\"Error in {__func__}: KeyError when parsing data: {status}\")\n",
    "        return 1\n",
    "\n",
    "\n",
    "#### TEST ####\n",
    "txt_logfile = \"gpu_log.txt\"\n",
    "write_status_to_txt_logfile(status, txt_logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a name=\"logging-to-csv\"></a> Logging to CSV\n",
    "\n",
    "CSV time-series data can be read by analysis programs and easily fed into MatPlotLib or other visualization software for graphical reporting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- CSV OUTPUT -------------------- #\n",
    "\n",
    "def format_csv_log_entry(status):\n",
    "    return f\"{status['day']}-{status['month']}\" \\\n",
    "           f\"-{status['year']},{status['time']},\" \\\n",
    "           f\"{status['temperature']},{status['power used']},\" \\\n",
    "           f\"{status['power max']},{status['fan']},\" \\\n",
    "           f\"{status['utilization']},{status['memory used']},\" \\\n",
    "           f\"{status['memory max']}\\n\"\n",
    "\n",
    "def write_status_to_csv_logfile(status, csv_logfile):\n",
    "    __func__ = \"write_status_to_csv_logfile\"\n",
    "    file_empty = os.stat(csv_logfile).st_size == 0\n",
    "    try:\n",
    "        with open(csv_logfile, mode=\"a\") as file:\n",
    "            if file_empty:\n",
    "                file.write(\"Date,Time,Temperature,Power Used, Power Max,Fan,\" \\\n",
    "                           \"Utilization,Memory Used,Memory Max\\n\")\n",
    "            entry = format_csv_log_entry(status)\n",
    "            file.write(entry)\n",
    "            file.close()\n",
    "        return 0\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error in {__func__}: {csv_logfile} not found.\")\n",
    "        return 1\n",
    "    except KeyError:\n",
    "        print(f\"Error in {__func__}: KeyError when parsing data: {status}\")\n",
    "        return 1\n",
    "\n",
    "\n",
    "#### TEST ####\n",
    "csv_logfile = \"gpu_log.csv\"\n",
    "write_status_to_csv_logfile(status, csv_logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"object-oriented-approach\"></a> [Object Oriented Approach](#toc)\n",
    "\n",
    "Using the cleansed functions above, it becomes clear that they act on a shared data flow. Additionally, the intermediate data is irrelevant to the user. Ultimately, the use is only interested in the output: accurate logfiles of the GPU status.\n",
    "\n",
    "```\n",
    "raw_status_data -> status -> logfile\n",
    "```\n",
    "\n",
    "Consequently, we can shield this flow from the user and expose only those functions that the user needs. Using an object oriented approach, we are left with the following object call:\n",
    "\n",
    "```PYTHON\n",
    "Status(\"gpu_log.txt\", \"gpu_log.csv\", debug=False)\n",
    "```\n",
    "\n",
    "This object will call NVIDIA-SMI and capture the raw data, parse the data into a valid status format and write the status data into both TXT and CSV formats.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "- Eventually, we will want automated notifications when the GPU temperature reaches a certain point. The GeForce RTX 2080 TI, for instance, has a maximum temperature of 89C according to [NVIDIA](https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2080-ti/)(under Specs > View Full Specs). Ergo, we want to receive a notification whenever the GPU temperature reaches, say, 85C.\n",
    "- What if the logfiles get too long? Ideally, there is a routine that inspects the logfiles and, if they are longer than a certain amount, deletes the top line during every write. This strategy will prevent the logging system from failing if the files get bloated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- META -----------\n",
      "Hostname: Seaborns-Mini.ngs.local\n",
      "TXT Logfile: gpu_log.txt\n",
      "CSV Logfile: gpu_log.csv\n",
      "Debug: True\n",
      "---------- STATUS ----------\n",
      "2021-03-04 @ 13:32:39\n",
      "Temperature: 95 C\n",
      "Utilization: 0%\n",
      "Fan: 0%\n",
      "Memory: 0 / 11019 MiB\n",
      "Power 1 / 250 W\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------- INSTANTIATE STATUS -------------------- #\n",
    "\n",
    "from custom.Status import Status\n",
    "\n",
    "status = Status(\"gpu_log.txt\", \"gpu_log.csv\", debug=True)\n",
    "status.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- WRITE LOGFILES -------------------- #\n",
    "\n",
    "status.write_status_to_logfiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is much cleaner than the functional approach and it exposes the user to the only thing they really need: passing in logfile names and getting the status output written to the logfiles. I exposed the `write_status_to_logfiles` function so that future developers can see the difference between instantiating the Status object and committing it to logfiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"automated-reporting\"></a> [Automated Reporting](#toc)\n",
    "\n",
    "ventually, we will want automated notifications when the GPU temperature reaches a certain point. The GeForce RTX 2080 TI, for instance, has a maximum temperature of 89C according to [NVIDIA](https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2080-ti/)(under Specs > View Full Specs). Ergo, we want to receive a notification whenever the GPU temperature reaches, say, 85C.\n",
    "\n",
    "The following technique works well but it requires that the system has `sendmail` installed and properly configured for sending email through the local firewalls.\n",
    "\n",
    "**TODO:**\n",
    "- Email notifications are annoying, slow, and bloat the mailboxes of their recipients. What if, instead of receiving emails, this system communicated important notifications via telegram (an end-to-end encrypted messaging service)? Future bots could be created and organized as contacts into channels that are organized by constellation. This method would keep the messages timely and organized (\\*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mail Delivery Status Report will be mailed to <seaborn>.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- SEND EMAIL NOTIFICATIONS -------------------- #\n",
    "\n",
    "import os\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def send_alert(alert, recipient, status):\n",
    "\n",
    "    subject = \"{} GPU Status Update\".format(status.hostname)\n",
    "\n",
    "    with open(\"templates/body.html\") as file:\n",
    "        body = file.read()\n",
    "        file.close()\n",
    "\n",
    "    body = body.format(status.hostname, alert_message,\n",
    "                       status.year, status.month, status.day,\n",
    "                       status.time, status.utilization,\n",
    "                       status.temperature, status.fan,\n",
    "                       status.power_used, status.power_max,\n",
    "                       status.memory_used, status.memory_max)\n",
    "\n",
    "    with open(\"templates/email.txt\", \"r\") as file:\n",
    "        email = file.read()\n",
    "        file.close()\n",
    "\n",
    "    email = email.format(recipient, subject, body)\n",
    "\n",
    "    with open(\"message.txt\", \"w\") as file:\n",
    "        file.write(email)\n",
    "        file.close\n",
    "\n",
    "    msg_status = os.popen(f\"sendmail -vt < message.txt\").read()\n",
    "    return msg_status\n",
    "\n",
    "#####\n",
    "\n",
    "status = Status(\"gpu_log.txt\", \"gpu_log.csv\", debug=True)\n",
    "recipient = \"seaborn.dev@gmail.com\"\n",
    "alert_message = \"Your GPU is practically barbequing in your rack.\"\n",
    "\n",
    "send_alert(alert_message, recipient, status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is added to the Status object so that, when instantiating an instance of this object or updating the status attributes, an email will automatically go out to the recipient if the temperature exceeds the set threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- CHECK AUTOREPORTING -------------------- #\n",
    "\n",
    "limits={\"temperature\": 85}\n",
    "status = Status(\"gpu_log.txt\", \"gpu_log.csv\", limits=limits, recipient=\"seaborn.dev@gmail.com\", debug=True)\n",
    "status.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Written by Austin Dial. Maintained by Alice Seaborn*\n",
    "\n",
    "\\* Yeah right! Instant messages can become bloated and otherwise totally ignored just like emails can. But messages are more easily handled by users do using Telegram is still a viable solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
